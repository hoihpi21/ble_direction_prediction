{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb # Import XGBoost\n",
    "\n",
    "# Directory for saving outputs\n",
    "output_result = 'xgb_polygon' # Changed output directory for XGBoost\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(output_result, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(\"21.5.2025.csv\")\n",
    "df = df[['timestamp', 'x_snap', 'y_snap']].dropna()\n",
    "df = df.sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "def iqr_filter(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    return series.between(lower, upper)\n",
    "\n",
    "mask = iqr_filter(df['x_snap']) & iqr_filter(df['y_snap'])\n",
    "df = df[mask].reset_index(drop=True)\n",
    "\n",
    "def kalman_filter_1d(data, process_var=1e-3, meas_var=0.108**2):\n",
    "    n = len(data)\n",
    "    xhat = np.zeros(n)\n",
    "    P = np.zeros(n)\n",
    "    xhat[0] = data[0]\n",
    "    P[0] = 1.0\n",
    "    for k in range(1, n):\n",
    "        xhat[k] = xhat[k-1]\n",
    "        P[k] = P[k-1] + process_var\n",
    "        K = P[k] / (P[k] + meas_var)\n",
    "        xhat[k] = xhat[k] + K * (data[k] - xhat[k])\n",
    "        P[k] = (1 - K) * P[k]\n",
    "    return xhat\n",
    "\n",
    "df['x_kalman'] = kalman_filter_1d(df['x_snap'].values)\n",
    "df['y_kalman'] = kalman_filter_1d(df['y_snap'].values)\n",
    "\n",
    "# --- Remove the last 8 points from the history trajectory ---\n",
    "# df = df.iloc[:-8].reset_index(drop=True) #\n",
    "\n",
    "# === NEW CODE FOR POLYGON FILTERING ===\n",
    "# Define the polygon vertices from your JSON\n",
    "polygon_json = \"{\\\"l1\\\":[[27.05,12.7,0],[81.19,12.7,0]],\\\"l2\\\":[[81.19,12.7,0],[81.19,28.87,0]],\\\"l3\\\":[[81.19,28.87,0],[27.05,28.87,0]],\\\"l4\\\":[[27.05,28.87,0],[27.05,12.7,0]]}\"\n",
    "polygon = json.loads(polygon_json)\n",
    "\n",
    "# Extract min/max x and y from the polygon to define a bounding box\n",
    "min_x_poly = min(line[0][0] for line in polygon.values())\n",
    "max_x_poly = max(line[0][0] for line in polygon.values())\n",
    "min_y_poly = min(line[0][1] for line in polygon.values())\n",
    "max_y_poly = max(line[0][1] for line in polygon.values())\n",
    "\n",
    "# Filter DataFrame based on the polygon boundaries\n",
    "df_filtered_polygon = df[\n",
    "    (df['x_kalman'] >= min_x_poly) & (df['x_kalman'] <= max_x_poly) &\n",
    "    (df['y_kalman'] >= min_y_poly) & (df['y_kalman'] <= max_y_poly)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# === Create sliding window input features ===\n",
    "window_size = 15\n",
    "\n",
    "# Use the polygon-filtered DataFrame here\n",
    "X, y = [], []\n",
    "for i in range(window_size, len(df_filtered_polygon) - 1):\n",
    "    window = df_filtered_polygon[['x_kalman', 'y_kalman']].iloc[i-window_size:i].values.flatten()\n",
    "    next_pos = df_filtered_polygon[['x_kalman', 'y_kalman']].iloc[i + 1].values\n",
    "    X.append(window)\n",
    "    y.append(next_pos)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_trainval, X_test_gt, y_trainval, y_test_gt = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.125, random_state=42)\n",
    "X_test, X_gt, y_test, y_gt = train_test_split(X_test_gt, y_test_gt, test_size=0.5, random_state=42)\n",
    "\n",
    "# --- XGBoost Model ---\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,      # Number of boosting rounds (trees)\n",
    "    learning_rate=0.15,     # Step size shrinkage\n",
    "    max_depth=5,           # Maximum depth of a tree\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror' # Objective function for regression\n",
    ")\n",
    "\n",
    "# Fit Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute RMSE\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Train RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "def predict_recursive(model, start_window, n_steps=20):\n",
    "    preds = []\n",
    "    window = start_window.copy()\n",
    "    for _ in range(n_steps):\n",
    "        # XGBoost predict function also expects 2D input\n",
    "        pred = model.predict(window.reshape(1, -1))[0]\n",
    "        preds.append(pred)\n",
    "        window = np.roll(window, -2)\n",
    "        window[-2:] = pred\n",
    "    return np.array(preds)\n",
    "\n",
    "start_window = X_gt[0]\n",
    "n_steps=10\n",
    "pred_path = predict_recursive(model, start_window, n_steps=n_steps)\n",
    "\n",
    "# Locate index in DataFrame\n",
    "start_x, start_y = start_window[-2], start_window[-1]\n",
    "\n",
    "# IMPORTANT: Use df_filtered_polygon to find the start_idx for the true_gt_path\n",
    "# This ensures consistency with the filtered data used for X and y\n",
    "dists = np.sqrt((df_filtered_polygon['x_kalman'] - start_x)**2 + (df_filtered_polygon['y_kalman'] - start_y)**2)\n",
    "start_idx = dists.idxmin()\n",
    "\n",
    "true_gt_path = df_filtered_polygon[['x_kalman', 'y_kalman']].iloc[start_idx + 1: start_idx + 1 + n_steps].values\n",
    "\n",
    "def euclidean(p1, p2):\n",
    "    return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "step_errors = [euclidean(p, g) for p, g in zip(pred_path, true_gt_path)]\n",
    "avg_error =  np.mean(step_errors)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(range(1, len(step_errors)+1), step_errors, marker='o', color='purple')\n",
    "plt.axhline(4.0, linestyle='--', color='red', label=\"4m Threshold\")\n",
    "plt.title(f\"Step-wise Average Euclidean Distance Error: {avg_error:.4f} meters\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Distance Error\")\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_result, \"stepwise_error_plot.png\")) # Use os.path.join for paths\n",
    "plt.show()\n",
    "\n",
    "# CSV\n",
    "rows = [{\n",
    "    'step': i+1,\n",
    "    'gt_x': gt[0],\n",
    "    'gt_y': gt[1],\n",
    "    'pred_x': pr[0],\n",
    "    'pred_y': pr[1],\n",
    "    'euclidean_distance': dist\n",
    "} for i, (gt, pr, dist) in enumerate(zip(true_gt_path, pred_path, step_errors))]\n",
    "\n",
    "df_error = pd.DataFrame(rows)\n",
    "df_error.to_csv(os.path.join(output_result, \"stepwise_prediction_vs_gt.csv\"), index=False) # Use os.path.join for paths\n",
    "print(f\"âœ… Exported: {os.path.join(output_result, 'stepwise_prediction_vs_gt.csv')} - Average Error: {avg_error:.4f}\")\n",
    "\n",
    "# === Full Combined Plot: History, Predicted Path, Ground Truth ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Reference polygon lines\n",
    "def draw_ref_lines_plot(ax_plot):\n",
    "    for line in polygon.values():\n",
    "        x = [p[0] for p in line]\n",
    "        y = [p[1] for p in line]\n",
    "        ax_plot.plot(x, y, 'k--', linewidth=1)\n",
    "\n",
    "draw_ref_lines_plot(plt.gca())\n",
    "\n",
    "# Raw history (all past data) - using the polygon-filtered data\n",
    "plt.plot(df_filtered_polygon['x_kalman'], df_filtered_polygon['y_kalman'], 'gray', alpha=0.5, label='Filtered History')\n",
    "plt.scatter(df_filtered_polygon['x_kalman'].iloc[0], df_filtered_polygon['y_kalman'].iloc[0], s=100, color='blue', marker='s', label='start')\n",
    "plt.scatter(df_filtered_polygon['x_kalman'].iloc[-1], df_filtered_polygon['y_kalman'].iloc[-1], s=100, color='red', marker='s', label='end')\n",
    "\n",
    "# Ground Truth path (green)\n",
    "plt.plot(true_gt_path[:, 0], true_gt_path[:, 1], 'g-o', label='Ground Truth')\n",
    "\n",
    "# Predicted path (blue dashed)\n",
    "plt.plot(pred_path[:, 0], pred_path[:, 1], 'b--o', label='Predicted Path')\n",
    "\n",
    "plt.title(\"Trajectory Overview: Filtered History, Ground Truth, and Prediction (XGBoost)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_result, \"full_trajectory_overview.png\")) # Use os.path.join for paths\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
